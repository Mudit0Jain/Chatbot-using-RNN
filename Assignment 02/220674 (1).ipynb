{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LIBRARIES"
      ],
      "metadata": {
        "id": "IrOd7vcQKgIF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPh4BVU229KS",
        "outputId": "01f77ed2-a6bc-4b10-bc23-1d6668c669d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download(\"maxent_ne_chunker\")\n",
        "nltk.download(\"words\")\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_s8wC3QyxCTV"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "dmrDNo2LKl-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_csv('/content/drive/MyDrive/rnn/train.csv')\n",
        "raw = raw.dropna()\n",
        "text = raw['text']\n",
        "categories = raw['category']"
      ],
      "metadata": {
        "id": "0RbmiG3M3RJ0"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "special_char_remove = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "extra_symbol_remove = re.compile('[^0-9a-z #+ ]')\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "XilhdtXeyNf-"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = special_char_remove.sub('  ', text)\n",
        "  text = extra_symbol_remove.sub('', text)\n",
        "  text = '  '.join(word for word in text.split() if word not in STOPWORDS)\n",
        "  return text"
      ],
      "metadata": {
        "id": "703Udta6zzOn"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.apply(clean_text)\n"
      ],
      "metadata": {
        "id": "XWCjpCsQ0b5m"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#train model\n"
      ],
      "metadata": {
        "id": "sVz2C4BZK-OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test , y_train, y_test = train_test_split(text , categories, test_size= 0.2, random_state= 22)"
      ],
      "metadata": {
        "id": "R-qr7ngx4Blq"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', LogisticRegression())])"
      ],
      "metadata": {
        "id": "8Eg6_Vaw0kVa"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(X_train, y_train)\n",
        "y_pred1 = lr.predict(X_test)\n"
      ],
      "metadata": {
        "id": "CxNhfngl2ZT0"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_pred1, y_test)"
      ],
      "metadata": {
        "id": "BwtK4B5z4P33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5800a070-a294-4ea8-9006-a147bb125721"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9730337078651685"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_pred1, y_test))"
      ],
      "metadata": {
        "id": "IIgnsxt24pcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7130aa59-62df-4a92-cda8-441b0fa01a18"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.95      0.96      0.95        91\n",
            "entertainment       0.96      0.99      0.97        72\n",
            "     politics       0.98      0.99      0.98        91\n",
            "        sport       1.00      0.99      1.00       102\n",
            "         tech       0.98      0.94      0.96        89\n",
            "\n",
            "     accuracy                           0.97       445\n",
            "    macro avg       0.97      0.97      0.97       445\n",
            " weighted avg       0.97      0.97      0.97       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimenting with random forest classifier"
      ],
      "metadata": {
        "id": "koiZ6KkFaApo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "AzkxzitmaPgZ"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('cdf', RandomForestClassifier())])"
      ],
      "metadata": {
        "id": "ejvWccUkZ_4b"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_train, y_train)\n",
        "y_pred2 = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "t1TU_ObwaYDc"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_pred2, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx5hlxYpahDc",
        "outputId": "3b137a67-532f-44d3-efb8-fe22802a2b95"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9595505617977528"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_pred1, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqXJJPXJakM3",
        "outputId": "8e110b37-07af-4a4b-96d1-c004b50a8f60"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.95      0.96      0.95        91\n",
            "entertainment       0.96      0.99      0.97        72\n",
            "     politics       0.98      0.99      0.98        91\n",
            "        sport       1.00      0.99      1.00       102\n",
            "         tech       0.98      0.94      0.96        89\n",
            "\n",
            "     accuracy                           0.97       445\n",
            "    macro avg       0.97      0.97      0.97       445\n",
            " weighted avg       0.97      0.97      0.97       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For testing perpose you may use the definition below"
      ],
      "metadata": {
        "id": "f4n5WRZcLGjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BELOW IT THE FUNCTION TO CHECK FOR TEST DATA\n",
        "INPUT THE COMBINED TEST DATA IT WILL SEPARATE LABELS FROM IT AND PREPROCESS IT TO GIVE CLASSIFICATION REPORT"
      ],
      "metadata": {
        "id": "vrufKEVhBne2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_model(link_test,lr):\n",
        "  test = pd.read_csv(link_test)\n",
        "  test_text = test['text']\n",
        "  test_categories = test['category']\n",
        "  test_text = test_text.apply(clean_text)\n",
        "  lr.fit(X_train, y_train)\n",
        "  y_pred1 = lr.predict(test_text)\n",
        "  print(classification_report(y_pred1, test_categories))"
      ],
      "metadata": {
        "id": "Nb9tEDqP6OFB"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''train_model(,)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_myQ2tzIBFD2",
        "outputId": "aba6c683-c3b8-474e-db00-03174dca9b74"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_model(,)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    }
  ]
}